{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torchvision.datasets as dset   # 데이터를 읽어옴\n",
    "import torchvision.transforms as transforms    # 불러온 이미지를 필요에 따라 변환\n",
    "from torch.utils.data import DataLoader   # 효율적인 학습을 위해 데이터를 어떤 규칙에 따라 정렬 또는 섞음\n",
    "\n",
    "# hyperparameter 설정\n",
    "batch_size = 256\n",
    "learning_rate = 0.0002\n",
    "num_epoch = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = dset.MNIST(\"./\", train=True, transform=transforms.ToTensor(), target_transform=None, download=True)\n",
    "mnist_test   = dset.MNIST(\"./\", train=False, transform=transforms.ToTensor(), target_transform=None, download=True)\n",
    "# train = True(학습데이터), False(테스트 데이터)\n",
    "# transform 데이터변형 (이미지 변형), transform.ToTensor():파이토치텐서로 변형\n",
    "# target_transform 라벨 변형\n",
    "# download : 현재 경로에 mnist데이터가 없을 경우 다운로드\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)\n",
    "test_loader  = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=2, drop_last=True)\n",
    "# dset.MNIST를 통해 정리된 데이터를 batch_size 개수만큼 묶는다\n",
    "# shuffle : 셔플 여부\n",
    "# num_workers : 데이터를 묶을때 사용할 프로세스 개수\n",
    "# drop_last : 묶고 남는 데이터를 버릴지 여부\n",
    "# train_loader test_loader는 순차적으로 모델에 데이터 전달\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 합성곱 신경망(CNN) 모델\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # super : CNN클래스의 부모 클래스인 nn.Module 초기화\n",
    "        \n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv2d(1,16,5),    # 1,28,28 => 16,24,24\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16,32,5),\n",
    "            nn.ReLU(),            # 16,24,24 => 32,20,20\n",
    "            nn.MaxPool2d(2,2),    # 32,20,20 => 32,10,10\n",
    "            nn.Conv2d(32,64,5),\n",
    "            nn.ReLU(),            # 32,10,10 => 64,6,6\n",
    "            nn.MaxPool2d(2,2)     # 64,6,6 => 64,3,3\n",
    "        )\n",
    "        # Conv2d(in_channels, out_channels, kernel_size)\n",
    "        # stride=1, padding=0 기본값\n",
    "        # MaxPool2d(kernel_size, stride)\n",
    "        # kernel_size : 한번에 훑는 영역의 크기\n",
    "        \n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(64*3*3, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100,10)\n",
    "        )\n",
    "        # [batch_size, 10]\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer(x)\n",
    "        out = out.view(batch_size, -1)\n",
    "        out = self.fc_layer(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN().to(device)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3067, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1900, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1070, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0736, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0724, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0559, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0462, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0262, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0452, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0352, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "loss_arr =[]\n",
    "for i in range(num_epoch):\n",
    "    for j,[image,label] in enumerate(train_loader):\n",
    "        x = image.to(device)\n",
    "        y_ = label.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(x)\n",
    "        loss = loss_func(output, y_)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if j%1000 == 0:\n",
    "            print(loss)\n",
    "            loss_arr.append(loss.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Test Data: 98.89823913574219\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터로 정확도 측정\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():   # 인퍼런스 모드를 위해 no_grad(기울기 계산안함)\n",
    "    for image, label in test_loader:   # 테스트로더에서 이미지와 정답 불러오기\n",
    "        x = image.to(device)\n",
    "        y_ = label.to(device)\n",
    "        \n",
    "        output = model.forward(x)     # 모델을 데이터에 넣고 결과 얻음\n",
    "        _,output_index = torch.max(output, 1)    # 최댓값 및 최댓값 인텍스를 뽑아냄\n",
    "        total += label.size(0)\n",
    "        correct += (output_index == y_).sum().float()\n",
    "        # 모델의 결과가 최댓값 인덱스와 라벨이 일치하는 개수를 correct에 추가\n",
    "        \n",
    "    print(\"Accuracy of Test Data: {}\".format(100*correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
